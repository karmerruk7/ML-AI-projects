{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP with weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error, r2_score\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, ReduceLROnPlateau\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# === Load and Engineer Data ===\n",
    "df = pd.read_csv(\"Energy_consumption.csv\", parse_dates=[\"Timestamp\"], index_col=\"Timestamp\")\n",
    "df = df[['Temperature', 'Humidity', 'EnergyConsumption']].dropna()\n",
    "\n",
    "# === Features === \n",
    "\n",
    "features = ['Temperature', 'Humidity']\n",
    "target = 'EnergyConsumption'\n",
    "\n",
    "# === Chronological Split ===\n",
    "train_end = int(0.8 * len(df)) # Split 80% for training and 20% for testing\n",
    "train_df = df.iloc[:train_end]\n",
    "test_df = df.iloc[train_end:]\n",
    "\n",
    "# === Normalize ===\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(train_df[features])\n",
    "y_train_scaled = scaler_y.fit_transform(train_df[[target]])\n",
    "\n",
    "X_test_scaled = scaler_X.transform(test_df[features])\n",
    "y_test_scaled = scaler_y.transform(test_df[[target]])\n",
    "\n",
    "# === Manual Chronological Validation Split ===\n",
    "val_split = int(0.9 * len(X_train_scaled))\n",
    "X_subtrain = X_train_scaled[:val_split]\n",
    "y_subtrain = y_train_scaled[:val_split]\n",
    "X_val = X_train_scaled[val_split:]\n",
    "y_val = y_train_scaled[val_split:]\n",
    "\n",
    "# === Build and Train MLP ===\n",
    "# The model is a simple feedforward neural network with two hidden layers\n",
    "# The first layer has 64 neurons and uses ReLU activation\n",
    "# The second layer has 32 neurons and also uses ReLU activation\n",
    "# The output layer has 1 neuron and no activation function\n",
    "# The model is compiled with the Adam optimizer and mean squared error loss function\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_subtrain.shape[1],)),\n",
    "    #Dropout(0.2),  # Randomly disables 20% of neurons during each training step (Prevents overfitting)\n",
    "    #Dense(64, activation='relu'),\n",
    "        # Not needed for this simple model\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True) # Prevents overfitting\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5) # Prevents overfitting\n",
    "\n",
    "model.fit(\n",
    "    X_subtrain, y_subtrain,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, lr_scheduler],\n",
    "    shuffle=False,  # Time series data should not be shuffled\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === Predict and Evaluate on Unseen Future Test Set ===\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test = scaler_y.inverse_transform(y_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n✅ Final Evaluation on Chronologically Held-Out Test Set\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "# ===  Plot Results ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test, label='Actual', marker='o')\n",
    "plt.plot(y_pred, label='Predicted', marker='x')\n",
    "plt.title(\"Energy Forecast on Future Weather (MLP, Time-Safe)\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Energy Consumption\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP with weather and non-weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# === Load and Engineer Data ===\n",
    "df = pd.read_csv(\"Energy_consumption.csv\", parse_dates=[\"Timestamp\"], index_col=\"Timestamp\")\n",
    "df = df[['Temperature', 'Humidity', 'Occupancy', 'SquareFootage', 'RenewableEnergy', 'HVACUsage', 'EnergyConsumption']].dropna()\n",
    "\n",
    "df['HVACUsage'] = df['HVACUsage'].str.strip().str.lower().map({'off': 0, 'on': 1}) # Convert HVAC usage to binary\n",
    "# === Features === \n",
    "\n",
    "features = ['Temperature', 'Humidity', 'Occupancy', 'SquareFootage', 'RenewableEnergy', 'HVACUsage']\n",
    "target = 'EnergyConsumption'\n",
    "\n",
    "# === Chronological Split ===\n",
    "train_end = int(0.8 * len(df)) # Split 80% for training and 20% for testing\n",
    "train_df = df.iloc[:train_end]\n",
    "test_df = df.iloc[train_end:]\n",
    "\n",
    "# === Normalize ===\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(train_df[features])\n",
    "y_train_scaled = scaler_y.fit_transform(train_df[[target]])\n",
    "\n",
    "X_test_scaled = scaler_X.transform(test_df[features])\n",
    "y_test_scaled = scaler_y.transform(test_df[[target]])\n",
    "\n",
    "# === Manual Chronological Validation Split ===\n",
    "val_split = int(0.9 * len(X_train_scaled))\n",
    "X_subtrain = X_train_scaled[:val_split]\n",
    "y_subtrain = y_train_scaled[:val_split]\n",
    "X_val = X_train_scaled[val_split:]\n",
    "y_val = y_train_scaled[val_split:]\n",
    "\n",
    "# === Build and Train MLP ===\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_subtrain.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True) # Prevents overfitting\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5) # Prevents overfitting\n",
    "\n",
    "model.fit(\n",
    "    X_subtrain, y_subtrain,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, lr_scheduler],\n",
    "    shuffle=False,  # Time series data should not be shuffled\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# === Predict and Evaluate on Unseen Future Test Set ===\n",
    "y_pred_scaled = model.predict(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test = scaler_y.inverse_transform(y_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n✅ Final Evaluation on Chronologically Held-Out Test Set\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}%\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "# ===  Plot Results ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test, label='Actual', marker='o')\n",
    "plt.plot(y_pred, label='Predicted', marker='x')\n",
    "plt.title(\"Energy Forecast on Future Weather (MLP, Time-Safe)\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Energy Consumption\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
